{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnNKqIw71l3HfJXfC5LvML"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# Connect drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTBjgeFSFusc","executionInfo":{"status":"ok","timestamp":1683271074371,"user_tz":-480,"elapsed":27060,"user":{"displayName":"Guillem Senabre","userId":"14399259858502030509"}},"outputId":"2718a5ce-aee7-49e2-a3a5-c34d9bb481a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skl5oMfoA6gx"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchtext.data as data\n","import torchtext\n","import numpy as np\n","import pandas as pd\n"]},{"cell_type":"code","source":["train = pd.read_csv('/content/drive/MyDrive/NCU/Data Science and Machine Learning/Assignment 3/Datasets/train.csv')\n","rwtrain = train.drop(train.columns[0], axis=1)"],"metadata":{"id":"UOEbCeLFCXu9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Text preprocessing"],"metadata":{"id":"IGYb0dsztTCl"}},{"cell_type":"code","source":["SENT_LENGTH = 40"],"metadata":{"id":"cgRX_5LVt0b6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the tokenizer\n","tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n","\n","# Define the fields for the dataset\n","text_field = data.Field(\n","    sequential=True, \n","    use_vocab=True, \n","    tokenize=tokenizer, \n","    batch_first=True,\n","    fix_length=SENT_LENGTH)  # set fix_length to the desired length of the sentence\n","\n","label_field = data.Field(\n","    sequential=False, use_vocab=False, dtype=torch.float32)\n","\n","# Create the dataset\n","fields = [('TEXT', text_field), ('LABEL', label_field)]\n","examples = [data.Example.fromlist([rwtrain.iloc[i,0], rwtrain.iloc[i,1]], fields) for i in range(len(rwtrain))]\n","dataset = data.Dataset(examples, fields)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"VyrWiqZbtSxO","executionInfo":{"status":"error","timestamp":1683271248105,"user_tz":-480,"elapsed":333,"user":{"displayName":"Guillem Senabre","userId":"14399259858502030509"}},"outputId":"c726731f-fa31-4346-e97f-6a9fa27270e0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a515777daa52>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the fields for the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m text_field = data.Field(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msequential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0muse_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Field'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IVYLWQszxW8A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GAN architecture (generator/discriminator)"],"metadata":{"id":"CKkCwkIDBIUQ"}},{"cell_type":"code","source":["# Define the generator network\n","class Generator(nn.Module):\n","    def __init__(self, input_size, output_size, hidden_size):\n","        super(Generator, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, hidden_size2)\n","        self.fc4 = nn.Linear(hidden_size2, output_size)\n","        \n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        return x\n","\n","# Define the discriminator network\n","class Discriminator(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Discriminator, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        x = self.sigmoid(x)\n","        return x"],"metadata":{"id":"L7zZaHNS1KcY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Hyperparameters"],"metadata":{"id":"tVSb5PlE1koO"}},{"cell_type":"code","source":["# Set hyperparameters\n","input_size = 32 # Size of the input data\n","output_size = 32 # Size of the output data\n","hidden_size = 128 # Size of the hidden layer\n","lr = 0.001 # Learning rate\n","num_epochs = 1000 # Number of training epochs\n","batch_size = 64 # Number of samples per batch"],"metadata":{"id":"FTMDnpxm1lpQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defining loss functions and optimizers"],"metadata":{"id":"6K-tuKTRBdAx"}},{"cell_type":"code","source":["# Initialize the generator and discriminator\n","G = Generator(input_size, output_size, hidden_size)\n","D = Discriminator(output_size, hidden_size)\n","\n","# Define the loss function and optimizer\n","criterion = nn.BCELoss()\n","G_optimizer = torch.optim.Adam(G.parameters(), lr=lr)\n","D_optimizer = torch.optim.Adam(D.parameters(), lr=lr)"],"metadata":{"id":"ehHaF4AP1xcI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training the GAN"],"metadata":{"id":"BM1ulPFSDW_y"}},{"cell_type":"code","source":["# Train the GAN (continued)\n","for epoch in range(num_epochs):\n","    for i in range(0, len(data), batch_size):\n","        # Train the discriminator\n","        D_optimizer.zero_grad()\n","        real_data = data[i:i+batch_size]\n","        real_labels = torch.ones(batch_size, 1)\n","        real_data_tensor = torch.tensor(real_data.values, dtype=torch.float32)\n","        fake_data = G(torch.randn(batch_size, input_size))\n","        fake_labels = torch.zeros(batch_size, 1)\n","        D_real_output = D(real_data_tensor)\n","        D_fake_output = D(fake_data.detach())\n","        D_real_loss = criterion(D_real_output, real_labels)\n","        D_fake_loss = criterion(D_fake_output, fake_labels)\n","        D_loss = D_real_loss + D_fake_loss\n","        D_loss.backward()\n","        D_optimizer.step()\n","        \n","        # Train the generator\n","        G_optimizer.zero_grad()\n","        fake_data = G(torch.randn(batch_size, input_size))\n","        fake_labels = torch.ones(batch_size, 1)\n","        G_output = D(fake_data)\n","        G_loss = criterion(G_output, fake_labels)\n","        G_loss.backward()\n","        G_optimizer.step()\n","\n","    # Print the loss for every 100th epoch\n","    if epoch % 100 == 0:\n","        print('Epoch [{}/{}], D_loss: {:.4f}, G_loss: {:.4f}'.format(epoch+1, num_epochs, D_loss.item(), G_loss.item()))\n"],"metadata":{"id":"7g0PSsMEDYQE","executionInfo":{"status":"error","timestamp":1683171735004,"user_tz":-480,"elapsed":343,"user":{"displayName":"Guillem Senabre","userId":"14399259858502030509"}},"colab":{"base_uri":"https://localhost:8080/","height":259},"outputId":"ce1bd720-769a-4bad-8611-8c8e499142b5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-76ffb3770a39>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mreal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mreal_data_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."]}]},{"cell_type":"code","source":["# Generate new data with the generator\n","num_samples = 2000 # Number of samples to generate\n","generated_data = G(torch.randn(num_samples, input_size)).detach().numpy()\n","\n","# Combine the original data and the generated data into a single dataframe\n","original_data = pd.read_csv('original_data.csv') # Replace 'original_data.csv' with the filename of your original data\n","all_data = pd.DataFrame(np.concatenate((original_data, generated_data), axis=0))\n","all_data.to_csv('all_data.csv', index=False) # Replace 'all_data.csv' with the filename for the combined data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"id":"rkZf67ETEyQp","executionInfo":{"status":"error","timestamp":1683093385679,"user_tz":-480,"elapsed":415,"user":{"displayName":"Guillem Senabre","userId":"14399259858502030509"}},"outputId":"89fc1216-e655-4b7f-dcb0-229f0abb008c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-cd360db95fa4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-40-9ceec9ce1689>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, gan, train_data, epochs, batch_size, latent_dim)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mfake_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Reshape the real sequences to match the shape of the fake sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mreal_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Combine real and fake sequences and their labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3200 into shape (32,1)"]}]}]}